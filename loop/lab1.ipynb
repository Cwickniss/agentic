{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "344e2c83",
   "metadata": {},
   "source": [
    "# What is an Agent?\n",
    "\n",
    "## Three competing definitions\n",
    "\n",
    "1. AI systems that can do work for you independently - Sam Altman\n",
    "\n",
    "2. A system in which an LLM controls the workflow - Anthropic\n",
    "\n",
    "3. An LLM agent runs tools in a loop to achieve a goal\n",
    "\n",
    "## The third one is the new, emerging definition\n",
    "\n",
    "But what does it mean?\n",
    "\n",
    "Let's make it real.\n",
    "\n",
    "## First up, to demystify 3 concepts:\n",
    "\n",
    "1. Tools - allow an LLM to call a function we write, perhaps to do math, query a database or call an API. Sounds spooky? It's another illusion. LLMs only generate tokens - they can't call functions!\n",
    "\n",
    "2. Structured outputs - require an LLM to respond in JSON according to a particular JSON spec\n",
    "\n",
    "3. Agent Framework - useful code which simplifies (1) and (2), amongst other things, making it easier to connect together LLM calls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda375f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, Runner, function_tool\n",
    "from dotenv import load_dotenv\n",
    "from rich.console import Console\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db51f44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\"Joke teller\", model=\"gpt-4.1-mini\")\n",
    "result = await Runner.run(agent, \"Tell me a joke for some data scientists\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6578f50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "todos = []\n",
    "completed = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c6d1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_todo_report(print: bool=False) -> str:\n",
    "    \"\"\"Get a report of all todos.\"\"\"\n",
    "    result = \"\"\n",
    "    for index, (todo, complete) in enumerate(zip(todos, completed)):\n",
    "        check = \"X\" if complete else \" \"\n",
    "        start = \"[strike][green]\" if complete else \"\"\n",
    "        end = \"[/strike][/green]\" if complete else \"\"\n",
    "        result += f\"Todo #{index + 1}: [{check}] {start}{todo}{end}\\n\"\n",
    "    if print:\n",
    "        Console().print(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90852adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_todo_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc82e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_todos(descriptions: list[str]) -> str:\n",
    "    \"\"\"Add new todos from a list of descriptions and return the full list\"\"\"\n",
    "    todos.extend(descriptions)\n",
    "    completed.extend([False] * len(descriptions))\n",
    "    return get_todo_report(print=True)\n",
    "\n",
    "def mark_complete(index: int) -> str:\n",
    "    \"\"\"Mark complete the todo at the given position (starting from 1) and return the full list\"\"\"\n",
    "    if 1 <= index <= len(todos):\n",
    "        completed[index - 1] = True\n",
    "    else:\n",
    "        return \"No todo at this index.\"\n",
    "    return get_todo_report(print=True)\n",
    "\n",
    "def list_todos() -> str:\n",
    "    \"\"\"Return the full list of todos with completed ones checked off\"\"\"\n",
    "    return get_todo_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6311520",
   "metadata": {},
   "outputs": [],
   "source": [
    "todos, completed = [], []\n",
    "\n",
    "create_todos([\"Buy groceries\", \"Finish lab1\", \"Go for a walk\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c21200",
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_complete(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db90e2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def create_todos(descriptions: list[str]) -> str:\n",
    "    \"\"\"Add new todos from a list of descriptions and return the full list\"\"\"\n",
    "    todos.extend(descriptions)\n",
    "    completed.extend([False] * len(descriptions))\n",
    "    return get_todo_report(print=True)\n",
    "\n",
    "@function_tool\n",
    "def mark_complete(index: int, completion_notes: str) -> str:\n",
    "    \"\"\"Mark complete the todo at the given position (starting from 1) and return the full list\n",
    "    \n",
    "    Args:\n",
    "        index: The 1-based index of the todo to mark as complete\n",
    "        completion_notes: Notes about how you completed the todo in rich console markup\n",
    "    \"\"\"\n",
    "    if 1 <= index <= len(todos):\n",
    "        completed[index - 1] = True\n",
    "    else:\n",
    "        return \"No todo at this index.\"\n",
    "    Console().print(completion_notes)\n",
    "    return get_todo_report(print=True)\n",
    "\n",
    "@function_tool\n",
    "def list_todos() -> str:\n",
    "    \"\"\"Return the full list of todos with completed ones checked off\"\"\"\n",
    "    return get_todo_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ace91f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_complete.params_json_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dc40fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "You are given a problem to solve, by using your todo tools to plan a list of steps, then carrying out each step in turn.\n",
    "Now use the todo list tools, create a plan, carry out the steps, and reply with the solution.\n",
    "Provide your solution in Rich console markup (e.g. [bold red]Error[/bold red]) to indicate colors and styles.\n",
    "\"\"\"\n",
    "tools = [create_todos, mark_complete, list_todos]\n",
    "agent = Agent(\"Puzzle Agent\", model=\"gpt-4.1-mini\", instructions=instructions, tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59f337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"A train leaves Boston at 2:00 pm traveling 60 mph. Another train leaves New York at 3:00 pm traveling 80 mph toward Boston. When do they meet?\"\n",
    "todos, completed = [], []\n",
    "response = await Runner.run(agent, task)\n",
    "Console().print(\"\\n\\n\" + response.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16c9252",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
