{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eae2b3a2-02d4-4061-9639-3a6f09810a44",
   "metadata": {},
   "source": [
    "# Fifth Agent Agent\n",
    "\n",
    "Introducing a critical agent - the agent that brings it all together.\n",
    "\n",
    "# Planning Agent\n",
    "\n",
    "There are a number of frameworks out there that support building Agentic Workflows.\n",
    "\n",
    "OpenAI has OpenAI Agents SDK, LangChain has LangGraph, and there's Autogen from Microsoft, Crew.ai and many others.  \n",
    "\n",
    "Each of these are abstractions on top of APIs to LLMs; some are lightweight, others come with significant functionality.\n",
    "\n",
    "It's also perfectly possible - and sometimes considerably easier - to build an agentic solution by calling LLMs directly.\n",
    "\n",
    "There's been considerable convergence on LLM APIs, and it's not clear that there's a need to sign up for one of the agent ecosystems for many use cases.\n",
    "\n",
    "Anthropic has an [insightful post](https://www.anthropic.com/research/building-effective-agents) on building effective Agentic architectures that's well worth a read.\n",
    "\n",
    "# We are going to use OpenAI Agents SDK for this Agent\n",
    "\n",
    "## And we're using Tools to give our Agent autonomy\n",
    "\n",
    "In our case, we're going to create an Agent that uses Tools to make decisions about what to do next.\n",
    "\n",
    "Let's see how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f171c2b-1943-43a5-85c6-0bcd84bdd3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a21ae3-da90-46a2-97f0-156cdd48542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai-agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bc09be7-0666-4fd4-8699-78e2c0cac93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, Runner, trace, function_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "612c8116-e4b6-4332-8bdb-d7c90b4aa9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "# Initialization\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "MODEL = \"gpt-4o\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0896c5f3-1ecc-4464-b913-2e7cfe29c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Scanner agent from before\n",
    "\n",
    "from price_agents.scanner_agent import ScannerAgent\n",
    "scanner = ScannerAgent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f25eed-e48a-4f9a-9817-4c0451378b40",
   "metadata": {},
   "source": [
    "# Our tools\n",
    "\n",
    "The next 3 cells have 3 **fake** functions that we will allow our LLM to call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f920a35-c58d-4961-8c3c-40d70157da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def scan_the_internet_for_bargains():\n",
    "    \"\"\" This tool scans the internet for great deals and gets a curated list of promising deals \"\"\"\n",
    "    print(f\"Scanning the internet\")\n",
    "    results = scanner.test_scan()\n",
    "    return results.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f885983-e054-43f3-86b4-6db9323216da",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def estimate_true_value(description: str) -> str:\n",
    "    \"\"\" This tool estimates how much a product is actually work, given a text description of the product \"\"\"\n",
    "    print(f\"Estimating true value of {description[:20]}...\")\n",
    "    return {\"description\": description, \"estimated_true_value\": 300}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93a42f55-0f75-44b1-830f-ee13d161cdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def notify_user_of_deal(description: str, deal_price: float, estimated_true_value: float):\n",
    "    \"\"\" This tool notified the user of a deal, given a description, a price and an estimated actual value \"\"\"\n",
    "    print(f\"Notifying user of {description} which costs {deal_price} and estimate is {estimated_true_value}\")\n",
    "    return {\"notification_sent\": \"ok\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1dd672-e77e-4f91-a66d-fe67f10ac093",
   "metadata": {},
   "source": [
    "## Telling the LLM about the tools it can use, with JSON\n",
    "\n",
    "\"Tool calling\" is giving an LLM the power to run code on your computer!\n",
    "\n",
    "Sounds a bit spooky?\n",
    "\n",
    "The way it works is a little more mundane. We give the LLM a description of each Tool and the parameters, and we let it inform us if it wants any tool to be run.\n",
    "\n",
    "It's not like OpenAI reaches in and runs a function. In the end, we have an if statement that calls our function if the model requests it.\n",
    "\n",
    "## OpenAI Agents SDK has made this easy for us\n",
    "\n",
    "The decorator `function_tools` around each of our functions automatically generates the description we need for the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54c1d76a-8744-46d0-afb3-d881820d876c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FunctionTool(name='scan_the_internet_for_bargains', description='This tool scans the internet for great deals and gets a curated list of promising deals', params_json_schema={'properties': {}, 'title': 'scan_the_internet_for_bargains_args', 'type': 'object', 'additionalProperties': False, 'required': []}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x118c23420>, strict_json_schema=True),\n",
       " FunctionTool(name='estimate_true_value', description='This tool estimates how much a product is actually work, given a text description of the product', params_json_schema={'properties': {'description': {'title': 'Description', 'type': 'string'}}, 'required': ['description'], 'title': 'estimate_true_value_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x1190feac0>, strict_json_schema=True),\n",
       " FunctionTool(name='notify_user_of_deal', description='This tool notified the user of a deal, given a description, a price and an estimated actual value', params_json_schema={'properties': {'description': {'title': 'Description', 'type': 'string'}, 'deal_price': {'title': 'Deal Price', 'type': 'number'}, 'estimated_true_value': {'title': 'Estimated True Value', 'type': 'number'}}, 'required': ['description', 'deal_price', 'estimated_true_value'], 'title': 'notify_user_of_deal_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x1190ff100>, strict_json_schema=True)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [scan_the_internet_for_bargains, estimate_true_value, notify_user_of_deal]\n",
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e088a008-fed8-4bc6-8041-8801adb3754c",
   "metadata": {},
   "source": [
    "## And.. MCP\n",
    "\n",
    "The Model Context Protocol from Anthropic is causing a lot of excitement.\n",
    "\n",
    "It gives us a really easy way to integrate new capabilities with our agent, as more tools.\n",
    "\n",
    "Here we will give our agent powers to write to our local filesystem in a directory \"sandbox\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "018b825e-df74-412f-a829-2a4c92cf1d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from agents.mcp import MCPServerStdio\n",
    "sandbox_path = os.path.abspath(os.path.join(os.getcwd(), \"sandbox\"))\n",
    "\n",
    "# parameters describe an MCP server\n",
    "files_params = {\"command\": \"npx\", \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", sandbox_path]}\n",
    "\n",
    "\n",
    "async with MCPServerStdio(params=files_params) as server:\n",
    "    file_tools = await server.list_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83173856-54d4-4afd-ac13-83fa15eca766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='read_file', description='Read the complete contents of a file from the file system. Handles various text encodings and provides detailed error messages if the file cannot be read. Use this tool when you need to examine the contents of a single file. Only works within allowed directories.', inputSchema={'type': 'object', 'properties': {'path': {'type': 'string'}}, 'required': ['path'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}),\n",
       " Tool(name='read_multiple_files', description=\"Read the contents of multiple files simultaneously. This is more efficient than reading files one by one when you need to analyze or compare multiple files. Each file's content is returned with its path as a reference. Failed reads for individual files won't stop the entire operation. Only works within allowed directories.\", inputSchema={'type': 'object', 'properties': {'paths': {'type': 'array', 'items': {'type': 'string'}}}, 'required': ['paths'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}),\n",
       " Tool(name='write_file', description='Create a new file or completely overwrite an existing file with new content. Use with caution as it will overwrite existing files without warning. Handles text content with proper encoding. Only works within allowed directories.', inputSchema={'type': 'object', 'properties': {'path': {'type': 'string'}, 'content': {'type': 'string'}}, 'required': ['path', 'content'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}),\n",
       " Tool(name='edit_file', description='Make line-based edits to a text file. Each edit replaces exact line sequences with new content. Returns a git-style diff showing the changes made. Only works within allowed directories.', inputSchema={'type': 'object', 'properties': {'path': {'type': 'string'}, 'edits': {'type': 'array', 'items': {'type': 'object', 'properties': {'oldText': {'type': 'string', 'description': 'Text to search for - must match exactly'}, 'newText': {'type': 'string', 'description': 'Text to replace with'}}, 'required': ['oldText', 'newText'], 'additionalProperties': False}}, 'dryRun': {'type': 'boolean', 'default': False, 'description': 'Preview changes using git-style diff format'}}, 'required': ['path', 'edits'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}),\n",
       " Tool(name='create_directory', description='Create a new directory or ensure a directory exists. Can create multiple nested directories in one operation. If the directory already exists, this operation will succeed silently. Perfect for setting up directory structures for projects or ensuring required paths exist. Only works within allowed directories.', inputSchema={'type': 'object', 'properties': {'path': {'type': 'string'}}, 'required': ['path'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}),\n",
       " Tool(name='list_directory', description='Get a detailed listing of all files and directories in a specified path. Results clearly distinguish between files and directories with [FILE] and [DIR] prefixes. This tool is essential for understanding directory structure and finding specific files within a directory. Only works within allowed directories.', inputSchema={'type': 'object', 'properties': {'path': {'type': 'string'}}, 'required': ['path'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}),\n",
       " Tool(name='directory_tree', description=\"Get a recursive tree view of files and directories as a JSON structure. Each entry includes 'name', 'type' (file/directory), and 'children' for directories. Files have no children array, while directories always have a children array (which may be empty). The output is formatted with 2-space indentation for readability. Only works within allowed directories.\", inputSchema={'type': 'object', 'properties': {'path': {'type': 'string'}}, 'required': ['path'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}),\n",
       " Tool(name='move_file', description='Move or rename files and directories. Can move files between directories and rename them in a single operation. If the destination exists, the operation will fail. Works across different directories and can be used for simple renaming within the same directory. Both source and destination must be within allowed directories.', inputSchema={'type': 'object', 'properties': {'source': {'type': 'string'}, 'destination': {'type': 'string'}}, 'required': ['source', 'destination'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}),\n",
       " Tool(name='search_files', description=\"Recursively search for files and directories matching a pattern. Searches through all subdirectories from the starting path. The search is case-insensitive and matches partial names. Returns full paths to all matching items. Great for finding files when you don't know their exact location. Only searches within allowed directories.\", inputSchema={'type': 'object', 'properties': {'path': {'type': 'string'}, 'pattern': {'type': 'string'}, 'excludePatterns': {'type': 'array', 'items': {'type': 'string'}, 'default': []}}, 'required': ['path', 'pattern'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}),\n",
       " Tool(name='get_file_info', description='Retrieve detailed metadata about a file or directory. Returns comprehensive information including size, creation time, last modified time, permissions, and type. This tool is perfect for understanding file characteristics without reading the actual content. Only works within allowed directories.', inputSchema={'type': 'object', 'properties': {'path': {'type': 'string'}}, 'required': ['path'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}),\n",
       " Tool(name='list_allowed_directories', description='Returns the list of directories that this server is allowed to access. Use this to understand which directories are available before trying to access files.', inputSchema={'type': 'object', 'properties': {}, 'required': []})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d195e6ad-c838-4a5f-ab3c-f3cb7f470fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an Autonomous AI Agent that makes use of tools to carry out your mission. Your mission is to find great deals on bargain products, and notify the user when you find them with a push notification and a written file.\"\n",
    "user_message = \"Your mission is to discover great deals on products. First you should scan the internet for bargain deals. Then for each deal, you should estimate its true value - how much it's actually worth. \"\n",
    "user_message += \"Finally, you should pick the single most compelling deal where the deal price is much lower than the estimated true value, and \"\n",
    "user_message += \"use your tools to send the user a push notification about that deal, and also use your tools to write or update a file called sandbox/deals.md with a description in markdown. \"\n",
    "user_message += \"You must only notify the user about one deal, and be sure to pick the most compelling deal, where the deal price is much lower than the estimated true value. Then just respond OK to indicate success.\"\n",
    "messages = [{\"role\": \"system\", \"content\": system_message},{\"role\": \"user\", \"content\": user_message}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215cad2e-a470-4cb7-ad78-3a13352bf4c5",
   "metadata": {},
   "source": [
    "### And here's where it comes together - just 2 lines of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3021830-b216-4013-8456-671a370f4450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning the internet\n",
      "Estimating true value of The Hisense R6 Serie...\n",
      "Estimating true value of The Poly Studio P21 ...\n",
      "Estimating true value of The Lenovo IdeaPad S...\n",
      "Estimating true value of The Dell G15 gaming ...\n",
      "Notifying user of The Poly Studio P21 is a 21.5-inch LED personal meeting display designed specifically for remote work and video conferencing. With a native resolution of 1080p, it provides crystal-clear video quality, featuring a privacy shutter and stereo speakers. This display includes a 1080p webcam with manual pan, tilt, and zoom control, along with an ambient light sensor to adjust the vanity lighting as needed. It also supports 5W wireless charging for mobile devices, making it an all-in-one solution for home offices. which costs 30.0 and estimate is 300.0\n",
      "RunResult:\n",
      "- Last agent: Agent(name=\"Planner\", ...)\n",
      "- Final output (str):\n",
      "    OK\n",
      "- 15 new item(s)\n",
      "- 4 raw response(s)\n",
      "- 0 input guardrail result(s)\n",
      "- 0 output guardrail result(s)\n",
      "(See `RunResult` for more details)\n"
     ]
    }
   ],
   "source": [
    "async with MCPServerStdio(params=files_params) as server:\n",
    "    agent = Agent(name=\"Planner\", instructions=system_message, model=\"gpt-4o\", tools=tools, mcp_servers=[server])\n",
    "    result = await Runner.run(agent, user_message)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67020429-93a3-4c26-b4ae-7c9c9f1d41a2",
   "metadata": {},
   "source": [
    "## And now - putting all of this into a Planning Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e30b1875-3a42-41c0-b217-9789090347b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from price_agents.autonomous_planning_agent import AutonomousPlanningAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "767db7b9-8d78-4d02-9b79-6c5e2dd8ddd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "root = logging.getLogger()\n",
    "root.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83fbf6c0-301e-4da0-b4e3-8f91ab4d686f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "DB = \"products_vectorstore\"\n",
    "client = chromadb.PersistentClient(path=DB)\n",
    "collection = client.get_or_create_collection('products')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "208067d9-8396-4f95-8dc8-a614c9a455df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning Agent is initializing\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[36m[Scanner Agent] Scanner Agent is initializing\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[36m[Scanner Agent] Scanner Agent is ready\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[33m[Frontier Agent] Initializing Frontier Agent\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is set up with DeepSeek\u001b[0m\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "INFO:root:\u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is ready\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[31m[Specialist Agent] Specialist Agent is initializing - connecting to modal\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[31m[Specialist Agent] Specialist Agent is ready\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[35m[Messaging Agent] Messaging Agent is initializing\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[35m[Messaging Agent] Messaging Agent has initialized Pushover and Claude\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning Agent is ready\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "agent = AutonomousPlanningAgent(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0121edc8-c309-4d04-b737-16a4235a83fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning Agent is kicking off a run\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning agent is calling scanner\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[36m[Scanner Agent] Scanner Agent is about to fetch deals from RSS feed\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[36m[Scanner Agent] Scanner Agent received 15 deals not already scraped\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[36m[Scanner Agent] Scanner Agent is calling OpenAI using Structured Output\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\u001b[40m\u001b[36m[Scanner Agent] Scanner Agent received 5 selected deals with price>0 from OpenAI\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning agent is estimating value\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is using Llama 3.2 to preprocess the description\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is vectorizing using all-MiniLM-L6-v2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d089ae960143bdb40ffcdf16372b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is performing a RAG search of the Chroma datastore to find 5 similar products\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[33m[Frontier Agent] Frontier Agent has found similar products\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is about to call DeepSeek with context including 5 similar products\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\u001b[40m\u001b[33m[Frontier Agent] Frontier Agent completed - predicting $699.99\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[31m[Specialist Agent] Specialist Agent is calling remote fine-tuned model\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[31m[Specialist Agent] Specialist Agent completed - predicting $500.00\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning agent is estimating value\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is using Llama 3.2 to preprocess the description\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is vectorizing using all-MiniLM-L6-v2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa15c026631a47e2bb4e0d5048d303ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is performing a RAG search of the Chroma datastore to find 5 similar products\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[33m[Frontier Agent] Frontier Agent has found similar products\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is about to call DeepSeek with context including 5 similar products\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\u001b[40m\u001b[33m[Frontier Agent] Frontier Agent completed - predicting $399.99\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[31m[Specialist Agent] Specialist Agent is calling remote fine-tuned model\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[31m[Specialist Agent] Specialist Agent completed - predicting $350.00\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning agent is estimating value\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is using Llama 3.2 to preprocess the description\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is vectorizing using all-MiniLM-L6-v2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74d136f5df9e487881227452057ce95f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is performing a RAG search of the Chroma datastore to find 5 similar products\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[33m[Frontier Agent] Frontier Agent has found similar products\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is about to call DeepSeek with context including 5 similar products\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\u001b[40m\u001b[33m[Frontier Agent] Frontier Agent completed - predicting $899.99\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[31m[Specialist Agent] Specialist Agent is calling remote fine-tuned model\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[31m[Specialist Agent] Specialist Agent completed - predicting $700.00\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning agent is estimating value\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is using Llama 3.2 to preprocess the description\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is vectorizing using all-MiniLM-L6-v2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19789a9bca9d43ae99e5540f7e15350d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is performing a RAG search of the Chroma datastore to find 5 similar products\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[33m[Frontier Agent] Frontier Agent has found similar products\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is about to call DeepSeek with context including 5 similar products\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\u001b[40m\u001b[33m[Frontier Agent] Frontier Agent completed - predicting $399.00\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[31m[Specialist Agent] Specialist Agent is calling remote fine-tuned model\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[31m[Specialist Agent] Specialist Agent completed - predicting $349.00\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning agent is estimating value\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is using Llama 3.2 to preprocess the description\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is vectorizing using all-MiniLM-L6-v2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f865200d2f204039978f3d9445c756b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is performing a RAG search of the Chroma datastore to find 5 similar products\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[33m[Frontier Agent] Frontier Agent has found similar products\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is about to call DeepSeek with context including 5 similar products\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\u001b[40m\u001b[33m[Frontier Agent] Frontier Agent completed - predicting $199.99\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[31m[Specialist Agent] Specialist Agent is calling remote fine-tuned model\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[31m[Specialist Agent] Specialist Agent completed - predicting $299.00\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning agent is notifying user\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[35m[Messaging Agent] Messaging Agent is using Claude to craft the message\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\u001b[40m\u001b[35m[Messaging Agent] Messaging Agent is sending a push notification\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[35m[Messaging Agent] Messaging Agent has completed\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning Agent completed with: RunResult:\n",
      "- Last agent: Agent(name=\"Planner\", ...)\n",
      "- Final output (str):\n",
      "    OK\n",
      "- 17 new item(s)\n",
      "- 4 raw response(s)\n",
      "- 0 input guardrail result(s)\n",
      "- 0 output guardrail result(s)\n",
      "(See `RunResult` for more details)\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/ed/miniconda3/envs/agentic/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/ed/miniconda3/envs/agentic/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/ed/miniconda3/envs/agentic/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/ed/miniconda3/envs/agentic/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/ed/miniconda3/envs/agentic/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/ed/miniconda3/envs/agentic/lib/python3.11/asyncio/base_events.py\", line 1921, in _run_once\n",
      "    handle = self._ready.popleft()\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "IndexError: pop from an empty deque\n"
     ]
    }
   ],
   "source": [
    "result = agent.plan()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c43c38-46d5-4186-880c-439ec975bb4b",
   "metadata": {},
   "source": [
    "### Check out the trace\n",
    "\n",
    "https://platform.openai.com/traces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3e15e5-dddc-4f2e-bbb4-ab9a5392eca7",
   "metadata": {},
   "source": [
    "# Finally - with a Gradio UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6f9da59-43c4-409f-8a93-5993e1d9e180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset memory back to 2 deals discovered in the past\n",
    "\n",
    "from deal_agent_framework import DealAgentFramework\n",
    "DealAgentFramework.reset_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805095ad-9d07-4869-9432-338f87fb65ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n",
      "[2025-04-09 19:49:14 -0400] [Agents] [INFO] \u001b[44m\u001b[37m[Agent Framework] Initializing Agent Framework\u001b[0m\n",
      "[2025-04-09 19:49:14 -0400] [Agents] [INFO] \u001b[44m\u001b[37m[Agent Framework] Initializing Agent Framework\u001b[0m\n",
      "[2025-04-09 19:49:14 -0400] [Agents] [INFO] \u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning Agent is initializing\u001b[0m\n",
      "[2025-04-09 19:49:14 -0400] [Agents] [INFO] \u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning Agent is initializing\u001b[0m\n",
      "[2025-04-09 19:49:14 -0400] [Agents] [INFO] \u001b[40m\u001b[36m[Scanner Agent] Scanner Agent is initializing\u001b[0m\n",
      "[2025-04-09 19:49:14 -0400] [Agents] [INFO] \u001b[40m\u001b[36m[Scanner Agent] Scanner Agent is initializing\u001b[0m\n",
      "[2025-04-09 19:49:14 -0400] [Agents] [INFO] \u001b[40m\u001b[36m[Scanner Agent] Scanner Agent is ready\u001b[0m\n",
      "[2025-04-09 19:49:14 -0400] [Agents] [INFO] \u001b[40m\u001b[36m[Scanner Agent] Scanner Agent is ready\u001b[0m\n",
      "[2025-04-09 19:49:14 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Initializing Frontier Agent\u001b[0m\n",
      "[2025-04-09 19:49:14 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Initializing Frontier Agent\u001b[0m\n",
      "[2025-04-09 19:49:14 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is set up with DeepSeek\u001b[0m\n",
      "[2025-04-09 19:49:14 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is set up with DeepSeek\u001b[0m\n",
      "[2025-04-09 19:49:14 -0400] [Agents] [INFO] Use pytorch device_name: mps\n",
      "[2025-04-09 19:49:14 -0400] [Agents] [INFO] Use pytorch device_name: mps\n",
      "[2025-04-09 19:49:14 -0400] [Agents] [INFO] Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "[2025-04-09 19:49:14 -0400] [Agents] [INFO] Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "[2025-04-09 19:49:15 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is ready\u001b[0m\n",
      "[2025-04-09 19:49:15 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is ready\u001b[0m\n",
      "[2025-04-09 19:49:15 -0400] [Agents] [INFO] \u001b[40m\u001b[31m[Specialist Agent] Specialist Agent is initializing - connecting to modal\u001b[0m\n",
      "[2025-04-09 19:49:15 -0400] [Agents] [INFO] \u001b[40m\u001b[31m[Specialist Agent] Specialist Agent is initializing - connecting to modal\u001b[0m\n",
      "[2025-04-09 19:49:15 -0400] [Agents] [INFO] \u001b[40m\u001b[31m[Specialist Agent] Specialist Agent is ready\u001b[0m\n",
      "[2025-04-09 19:49:15 -0400] [Agents] [INFO] \u001b[40m\u001b[31m[Specialist Agent] Specialist Agent is ready\u001b[0m\n",
      "[2025-04-09 19:49:15 -0400] [Agents] [INFO] \u001b[40m\u001b[35m[Messaging Agent] Messaging Agent is initializing\u001b[0m\n",
      "[2025-04-09 19:49:15 -0400] [Agents] [INFO] \u001b[40m\u001b[35m[Messaging Agent] Messaging Agent is initializing\u001b[0m\n",
      "[2025-04-09 19:49:15 -0400] [Agents] [INFO] \u001b[40m\u001b[35m[Messaging Agent] Messaging Agent has initialized Pushover and Claude\u001b[0m\n",
      "[2025-04-09 19:49:15 -0400] [Agents] [INFO] \u001b[40m\u001b[35m[Messaging Agent] Messaging Agent has initialized Pushover and Claude\u001b[0m\n",
      "[2025-04-09 19:49:15 -0400] [Agents] [INFO] \u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning Agent is ready\u001b[0m\n",
      "[2025-04-09 19:49:15 -0400] [Agents] [INFO] \u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning Agent is ready\u001b[0m\n",
      "[2025-04-09 19:49:15 -0400] [Agents] [INFO] \u001b[44m\u001b[37m[Agent Framework] Agent Framework is ready\u001b[0m\n",
      "[2025-04-09 19:49:15 -0400] [Agents] [INFO] \u001b[44m\u001b[37m[Agent Framework] Agent Framework is ready\u001b[0m\n",
      "[2025-04-09 19:49:15 -0400] [Agents] [INFO] Kicking off Planning Agent\n",
      "[2025-04-09 19:49:15 -0400] [Agents] [INFO] Kicking off Planning Agent\n",
      "[2025-04-09 19:49:15 -0400] [Agents] [INFO] \u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning Agent is kicking off a run\u001b[0m\n",
      "[2025-04-09 19:49:15 -0400] [Agents] [INFO] \u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning Agent is kicking off a run\u001b[0m\n",
      "Secure MCP Filesystem Server running on stdio\n",
      "Allowed directories: [ \u001b[32m'/Users/ed/dev/agentic/workshop/sandbox'\u001b[39m ]\n",
      "[2025-04-09 19:49:18 -0400] [Agents] [INFO] HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "[2025-04-09 19:49:18 -0400] [Agents] [INFO] HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "[2025-04-09 19:49:18 -0400] [Agents] [INFO] \u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning agent is calling scanner\u001b[0m\n",
      "[2025-04-09 19:49:18 -0400] [Agents] [INFO] \u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning agent is calling scanner\u001b[0m\n",
      "[2025-04-09 19:49:18 -0400] [Agents] [INFO] \u001b[40m\u001b[36m[Scanner Agent] Scanner Agent is about to fetch deals from RSS feed\u001b[0m\n",
      "[2025-04-09 19:49:18 -0400] [Agents] [INFO] \u001b[40m\u001b[36m[Scanner Agent] Scanner Agent is about to fetch deals from RSS feed\u001b[0m\n",
      "[2025-04-09 19:49:20 -0400] [Agents] [INFO] HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "[2025-04-09 19:49:20 -0400] [Agents] [INFO] HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "[2025-04-09 19:49:24 -0400] [Agents] [INFO] \u001b[40m\u001b[36m[Scanner Agent] Scanner Agent received 15 deals not already scraped\u001b[0m\n",
      "[2025-04-09 19:49:24 -0400] [Agents] [INFO] \u001b[40m\u001b[36m[Scanner Agent] Scanner Agent received 15 deals not already scraped\u001b[0m\n",
      "[2025-04-09 19:49:24 -0400] [Agents] [INFO] \u001b[40m\u001b[36m[Scanner Agent] Scanner Agent is calling OpenAI using Structured Output\u001b[0m\n",
      "[2025-04-09 19:49:24 -0400] [Agents] [INFO] \u001b[40m\u001b[36m[Scanner Agent] Scanner Agent is calling OpenAI using Structured Output\u001b[0m\n",
      "[2025-04-09 19:49:33 -0400] [Agents] [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-04-09 19:49:33 -0400] [Agents] [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-04-09 19:49:33 -0400] [Agents] [INFO] \u001b[40m\u001b[36m[Scanner Agent] Scanner Agent received 5 selected deals with price>0 from OpenAI\u001b[0m\n",
      "[2025-04-09 19:49:33 -0400] [Agents] [INFO] \u001b[40m\u001b[36m[Scanner Agent] Scanner Agent received 5 selected deals with price>0 from OpenAI\u001b[0m\n",
      "[2025-04-09 19:49:36 -0400] [Agents] [INFO] HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "[2025-04-09 19:49:36 -0400] [Agents] [INFO] HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "[2025-04-09 19:49:37 -0400] [Agents] [INFO] HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "[2025-04-09 19:49:37 -0400] [Agents] [INFO] HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "[2025-04-09 19:49:37 -0400] [Agents] [INFO] \u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning agent is estimating value\u001b[0m\n",
      "[2025-04-09 19:49:37 -0400] [Agents] [INFO] \u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning agent is estimating value\u001b[0m\n",
      "[2025-04-09 19:49:37 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is using Llama 3.2 to preprocess the description\u001b[0m\n",
      "[2025-04-09 19:49:37 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is using Llama 3.2 to preprocess the description\u001b[0m\n",
      "[2025-04-09 19:49:38 -0400] [Agents] [INFO] HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-04-09 19:49:38 -0400] [Agents] [INFO] HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-04-09 19:49:38 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is vectorizing using all-MiniLM-L6-v2\u001b[0m\n",
      "[2025-04-09 19:49:38 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is vectorizing using all-MiniLM-L6-v2\u001b[0m\n",
      "Batches: 100%|████████████████████████████████████| 1/1 [00:00<00:00,  4.79it/s]\n",
      "[2025-04-09 19:49:38 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is performing a RAG search of the Chroma datastore to find 5 similar products\u001b[0m\n",
      "[2025-04-09 19:49:38 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is performing a RAG search of the Chroma datastore to find 5 similar products\u001b[0m\n",
      "[2025-04-09 19:49:38 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent has found similar products\u001b[0m\n",
      "[2025-04-09 19:49:38 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent has found similar products\u001b[0m\n",
      "[2025-04-09 19:49:38 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is about to call DeepSeek with context including 5 similar products\u001b[0m\n",
      "[2025-04-09 19:49:38 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is about to call DeepSeek with context including 5 similar products\u001b[0m\n",
      "[2025-04-09 19:49:38 -0400] [Agents] [INFO] HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-04-09 19:49:38 -0400] [Agents] [INFO] HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-04-09 19:49:41 -0400] [Agents] [INFO] HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "[2025-04-09 19:49:41 -0400] [Agents] [INFO] HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n",
      "[2025-04-09 19:49:42 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent completed - predicting $999.99\u001b[0m\n",
      "[2025-04-09 19:49:42 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent completed - predicting $999.99\u001b[0m\n",
      "[2025-04-09 19:49:42 -0400] [Agents] [INFO] \u001b[40m\u001b[31m[Specialist Agent] Specialist Agent is calling remote fine-tuned model\u001b[0m\n",
      "[2025-04-09 19:49:42 -0400] [Agents] [INFO] \u001b[40m\u001b[31m[Specialist Agent] Specialist Agent is calling remote fine-tuned model\u001b[0m\n",
      "[2025-04-09 19:50:16 -0400] [Agents] [INFO] \u001b[40m\u001b[31m[Specialist Agent] Specialist Agent completed - predicting $500.00\u001b[0m\n",
      "[2025-04-09 19:50:16 -0400] [Agents] [INFO] \u001b[40m\u001b[31m[Specialist Agent] Specialist Agent completed - predicting $500.00\u001b[0m\n",
      "[2025-04-09 19:50:16 -0400] [Agents] [INFO] \u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning agent is estimating value\u001b[0m\n",
      "[2025-04-09 19:50:16 -0400] [Agents] [INFO] \u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning agent is estimating value\u001b[0m\n",
      "[2025-04-09 19:50:16 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is using Llama 3.2 to preprocess the description\u001b[0m\n",
      "[2025-04-09 19:50:16 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is using Llama 3.2 to preprocess the description\u001b[0m\n",
      "[2025-04-09 19:50:17 -0400] [Agents] [INFO] HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-04-09 19:50:17 -0400] [Agents] [INFO] HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-04-09 19:50:17 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is vectorizing using all-MiniLM-L6-v2\u001b[0m\n",
      "[2025-04-09 19:50:17 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is vectorizing using all-MiniLM-L6-v2\u001b[0m\n",
      "Batches: 100%|████████████████████████████████████| 1/1 [00:00<00:00, 10.36it/s]\n",
      "[2025-04-09 19:50:17 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is performing a RAG search of the Chroma datastore to find 5 similar products\u001b[0m\n",
      "[2025-04-09 19:50:17 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is performing a RAG search of the Chroma datastore to find 5 similar products\u001b[0m\n",
      "[2025-04-09 19:50:17 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent has found similar products\u001b[0m\n",
      "[2025-04-09 19:50:17 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent has found similar products\u001b[0m\n",
      "[2025-04-09 19:50:17 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is about to call DeepSeek with context including 5 similar products\u001b[0m\n",
      "[2025-04-09 19:50:17 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is about to call DeepSeek with context including 5 similar products\u001b[0m\n",
      "[2025-04-09 19:50:17 -0400] [Agents] [INFO] HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-04-09 19:50:17 -0400] [Agents] [INFO] HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-04-09 19:50:27 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent completed - predicting $179.99\u001b[0m\n",
      "[2025-04-09 19:50:27 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent completed - predicting $179.99\u001b[0m\n",
      "[2025-04-09 19:50:27 -0400] [Agents] [INFO] \u001b[40m\u001b[31m[Specialist Agent] Specialist Agent is calling remote fine-tuned model\u001b[0m\n",
      "[2025-04-09 19:50:27 -0400] [Agents] [INFO] \u001b[40m\u001b[31m[Specialist Agent] Specialist Agent is calling remote fine-tuned model\u001b[0m\n",
      "[2025-04-09 19:50:29 -0400] [Agents] [INFO] \u001b[40m\u001b[31m[Specialist Agent] Specialist Agent completed - predicting $170.00\u001b[0m\n",
      "[2025-04-09 19:50:29 -0400] [Agents] [INFO] \u001b[40m\u001b[31m[Specialist Agent] Specialist Agent completed - predicting $170.00\u001b[0m\n",
      "[2025-04-09 19:50:29 -0400] [Agents] [INFO] \u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning agent is estimating value\u001b[0m\n",
      "[2025-04-09 19:50:29 -0400] [Agents] [INFO] \u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning agent is estimating value\u001b[0m\n",
      "[2025-04-09 19:50:29 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is using Llama 3.2 to preprocess the description\u001b[0m\n",
      "[2025-04-09 19:50:29 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is using Llama 3.2 to preprocess the description\u001b[0m\n",
      "[2025-04-09 19:50:30 -0400] [Agents] [INFO] HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-04-09 19:50:30 -0400] [Agents] [INFO] HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-04-09 19:50:30 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is vectorizing using all-MiniLM-L6-v2\u001b[0m\n",
      "[2025-04-09 19:50:30 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is vectorizing using all-MiniLM-L6-v2\u001b[0m\n",
      "Batches: 100%|████████████████████████████████████| 1/1 [00:00<00:00, 12.34it/s]\n",
      "[2025-04-09 19:50:30 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is performing a RAG search of the Chroma datastore to find 5 similar products\u001b[0m\n",
      "[2025-04-09 19:50:30 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is performing a RAG search of the Chroma datastore to find 5 similar products\u001b[0m\n",
      "[2025-04-09 19:50:30 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent has found similar products\u001b[0m\n",
      "[2025-04-09 19:50:30 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent has found similar products\u001b[0m\n",
      "[2025-04-09 19:50:30 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is about to call DeepSeek with context including 5 similar products\u001b[0m\n",
      "[2025-04-09 19:50:30 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is about to call DeepSeek with context including 5 similar products\u001b[0m\n",
      "[2025-04-09 19:50:30 -0400] [Agents] [INFO] HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-04-09 19:50:30 -0400] [Agents] [INFO] HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-04-09 19:50:36 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent completed - predicting $349.99\u001b[0m\n",
      "[2025-04-09 19:50:36 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent completed - predicting $349.99\u001b[0m\n",
      "[2025-04-09 19:50:36 -0400] [Agents] [INFO] \u001b[40m\u001b[31m[Specialist Agent] Specialist Agent is calling remote fine-tuned model\u001b[0m\n",
      "[2025-04-09 19:50:36 -0400] [Agents] [INFO] \u001b[40m\u001b[31m[Specialist Agent] Specialist Agent is calling remote fine-tuned model\u001b[0m\n",
      "[2025-04-09 19:50:37 -0400] [Agents] [INFO] \u001b[40m\u001b[31m[Specialist Agent] Specialist Agent completed - predicting $350.00\u001b[0m\n",
      "[2025-04-09 19:50:37 -0400] [Agents] [INFO] \u001b[40m\u001b[31m[Specialist Agent] Specialist Agent completed - predicting $350.00\u001b[0m\n",
      "[2025-04-09 19:50:37 -0400] [Agents] [INFO] \u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning agent is estimating value\u001b[0m\n",
      "[2025-04-09 19:50:37 -0400] [Agents] [INFO] \u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning agent is estimating value\u001b[0m\n",
      "[2025-04-09 19:50:37 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is using Llama 3.2 to preprocess the description\u001b[0m\n",
      "[2025-04-09 19:50:37 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is using Llama 3.2 to preprocess the description\u001b[0m\n",
      "[2025-04-09 19:50:38 -0400] [Agents] [INFO] HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-04-09 19:50:38 -0400] [Agents] [INFO] HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-04-09 19:50:38 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is vectorizing using all-MiniLM-L6-v2\u001b[0m\n",
      "[2025-04-09 19:50:38 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is vectorizing using all-MiniLM-L6-v2\u001b[0m\n",
      "Batches: 100%|████████████████████████████████████| 1/1 [00:00<00:00, 11.27it/s]\n",
      "[2025-04-09 19:50:38 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is performing a RAG search of the Chroma datastore to find 5 similar products\u001b[0m\n",
      "[2025-04-09 19:50:38 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is performing a RAG search of the Chroma datastore to find 5 similar products\u001b[0m\n",
      "[2025-04-09 19:50:38 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent has found similar products\u001b[0m\n",
      "[2025-04-09 19:50:38 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent has found similar products\u001b[0m\n",
      "[2025-04-09 19:50:38 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is about to call DeepSeek with context including 5 similar products\u001b[0m\n",
      "[2025-04-09 19:50:38 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is about to call DeepSeek with context including 5 similar products\u001b[0m\n",
      "[2025-04-09 19:50:39 -0400] [Agents] [INFO] HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-04-09 19:50:39 -0400] [Agents] [INFO] HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-04-09 19:50:43 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent completed - predicting $499.00\u001b[0m\n",
      "[2025-04-09 19:50:43 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent completed - predicting $499.00\u001b[0m\n",
      "[2025-04-09 19:50:43 -0400] [Agents] [INFO] \u001b[40m\u001b[31m[Specialist Agent] Specialist Agent is calling remote fine-tuned model\u001b[0m\n",
      "[2025-04-09 19:50:43 -0400] [Agents] [INFO] \u001b[40m\u001b[31m[Specialist Agent] Specialist Agent is calling remote fine-tuned model\u001b[0m\n",
      "[2025-04-09 19:50:45 -0400] [Agents] [INFO] \u001b[40m\u001b[31m[Specialist Agent] Specialist Agent completed - predicting $349.00\u001b[0m\n",
      "[2025-04-09 19:50:45 -0400] [Agents] [INFO] \u001b[40m\u001b[31m[Specialist Agent] Specialist Agent completed - predicting $349.00\u001b[0m\n",
      "[2025-04-09 19:50:45 -0400] [Agents] [INFO] \u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning agent is estimating value\u001b[0m\n",
      "[2025-04-09 19:50:45 -0400] [Agents] [INFO] \u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning agent is estimating value\u001b[0m\n",
      "[2025-04-09 19:50:45 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is using Llama 3.2 to preprocess the description\u001b[0m\n",
      "[2025-04-09 19:50:45 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is using Llama 3.2 to preprocess the description\u001b[0m\n",
      "[2025-04-09 19:50:46 -0400] [Agents] [INFO] HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-04-09 19:50:46 -0400] [Agents] [INFO] HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-04-09 19:50:46 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is vectorizing using all-MiniLM-L6-v2\u001b[0m\n",
      "[2025-04-09 19:50:46 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is vectorizing using all-MiniLM-L6-v2\u001b[0m\n",
      "Batches: 100%|████████████████████████████████████| 1/1 [00:00<00:00,  9.34it/s]\n",
      "[2025-04-09 19:50:46 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is performing a RAG search of the Chroma datastore to find 5 similar products\u001b[0m\n",
      "[2025-04-09 19:50:46 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is performing a RAG search of the Chroma datastore to find 5 similar products\u001b[0m\n",
      "[2025-04-09 19:50:46 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent has found similar products\u001b[0m\n",
      "[2025-04-09 19:50:46 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent has found similar products\u001b[0m\n",
      "[2025-04-09 19:50:46 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is about to call DeepSeek with context including 5 similar products\u001b[0m\n",
      "[2025-04-09 19:50:46 -0400] [Agents] [INFO] \u001b[40m\u001b[33m[Frontier Agent] Frontier Agent is about to call DeepSeek with context including 5 similar products\u001b[0m\n",
      "[2025-04-09 19:50:46 -0400] [Agents] [INFO] HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-04-09 19:50:46 -0400] [Agents] [INFO] HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "!python price_is_right.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df197f7-7ed4-4b24-a333-80ffda9d7032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
